# Open targets internal deployment guide

## Overview

Using project: `open-targets-genetics-dev`.

Currently the genetics team provides input files in a GCP bucket `gs://genetics-portal-dev-staging` (`staging`). Some of
these files are static, others are annotated with a date (variously YYMMDD and DDMMYY).

A _subset_ of these files are then _manually_ copied by the BE team to `gs://genetics-portal-dev-data` (`dev`) in a
bucket corresponding to the release.

The files in `dev` are used to run the pipeline, typically using Dataproc.

| Configuration field | Likely staging location | Standard dev location |
| --- | --- | --- |
| `variant-index.raw` | *provided by data team* | /variant-annotation/<date>/variant-annotation.parquet |
| `ensembl.lut` | *generated by BE* | /lut/homo_sapiens_core_105_38_genes.json.gz |
| `vep.homo-sapiens-cons-scores` | *should be in staging bucket* | /lut/vep_consequences.tsv |
| `interval.path` |v2g/interval/\* | /v2g/interval/\*/\*/<date>/data.parquet |
| `qtl.path` | v2g/qtl/\<date\>/ | v2g/qlt/\<date\> |
| `variant-gene.weights` | *carried over from previous release* | lut/v2g_scoring_source_weights.date.json |
| `variant-disease.studies` | v2d/\<date\>/studies.parquet | v2d/studies.parquet |
| `variant-disease.toploci` | v2d/\<date\>/toploci.parquet | v2d/toploci.parquet|
| `variant-disease.finemapping` | v2d/\<date\>/finemapping.parquet/ | v2d/finemapping.parquet |
| `variant-disease.ld` | v2d/\<date\>/ld.parquet/ | v2d/ld.parquet |
| `variant-disease.overlapping` | v2d/\<date\>/locus_overlap.parquet | v2d/locus_overlap.parquet |
| `variant-disease.coloc` | coloc/\<date\>/coloc_processed_w_betas.parquet/ | v2d/coloc_processed_w_betas.parquet |
| `variant-disease.trait_efo` | v2d/\<date\>/trait_efo-2021-11-16.parquet | v2d/trait_efo.parquet |

### Variant index section

The variant index comes in parquet _from the data team_ after filtering the latest Gnomad release.

If there is no new update keep using the last one used. Currently, the variant annotation is version 190129.

### Ensembl

Genetics team do not provide the Ensembl file: we have to download it ourselves and generate the input.

It is a configuration place to bring the latest reference gene table from Ensembl. To generate this file to need to
follow the instructions [from this script](https://github.com/opentargets/genetics-backend/tree/master/makeLUTs). And
the command I use is this as an example

```python create_genes_dictionary.py -o "./" -z -n homo_sapiens_core_104_38```

### VEP consequences

The TSV file is provided by the _genetics team_. If the file is not present in the staging bucket ask the Genetics team
for the most recent version.

### Recipe: set up deployment machine

We need a VM to run deployments from. Typically this only needs to be done once and then we can use the machine for
future releases.

```bash
# install dependencies
sudo apt install -y git \
tmux tree wget \
libgl1-mesa-glx libegl1-mesa libxrandr2 libxrandr2 libxss1 libxcursor1 libxcomposite1 libasound2 libxi6 libxtst6

wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh
bash ~/miniconda.sh -p $HOME/miniconda
source ~/.bashrc

# get repositories
git clone https://github.com/opentargets/genetics-backend.git

# set up conda environments
cd genetics-backend && conda env create -f environment.yaml

```

### Recipe: get all inputs

Use the VM in the `open-target-genetics-dev` machine called `gp-deploy`. The VM is preconfigured with the necessary
utilities to run a release.

- [ ] clone required repository: `git clone git@github.com:opentargets/genetics-backend.git`
- [ ] set up environment: `conda activate backend-genetics`
- [ ] update Ensembl version and run script: `python create_genes_dictionary.py -o "./" -z -n homo_sapiens_core_105_38`
- [ ] add ensembl file to bucket

```bash
#!/bin/bash

set -x

echo "Preparing to copy genetics resources"
# -n flag so as not to clobber existing. 
gscp='gsutil -m cp -n'
staging='gs://genetics-portal-dev-staging'
dev_data='gs://genetics-portal-dev-data'
release='22.01'
inputs=$dev_data/$release/inputs
outputs=$dev_data/$release/outputs
lut=$inputs/lut
v2d=$inputs/v2d
v2g=$inputs/v2g
va=$inputs/variant-annotation
sa=$outputs/sa

echo "copy static files from previous release"
# copy static files from previous release
previous_inputs='gs://genetics-portal-dev-data/21.10/inputs'
#lut
lut_files=('biofeature_labels.json' 'vep_consequences.tsv' 'v2g_scoring_source_weights.141021.json')
for i in "${lut_files[@]}"
do
  echo "Copy $i to $lut"
  $gscp $previous_inputs/lut/$i $lut/$i
done

echo "Add date versioned LUT inputs"
# add date versioned lut inputs
v2g_dl='200130'
v2g_ssw='141021'
b_lut='220105'
$gscp $staging/lut/biofeature_labels/$b_lut/biofeature_labels.w_composites.json \
"$lut/biofeature_lut_$b_lut.w_composites.json"

echo "Add versioned v2d inputs"
trait_efo='2021-01-14'
v2d_version='220113'
v2d_files=( 'studies.parquet' \
            'ld_analysis_input.tsv' \
            'locus_overlap.parquet' \
            $"trait_efo-$trait_efo.parquet" \
            'toploci.parquet' \
            'ld.parquet')
for i in "${v2d_files[@]}"
do
	echo "Copy $i to $v2d"
    $gscp $staging/v2d/$v2d_version/$i $v2d/$i
done

echo "Add versioned v2g inputs"
qtl='220105'
$gscp -r $staging/v2g/interval $v2g
$gscp -r $staging/v2g/qtl/$qtl $v2g/qtl/

echo "Add variant annotations from previous release"
# In theory these files could be updated in future, but we're still using the Jan 2019 ones
# so they are effectively static.
$gscp -r $previous_inputs/variant-annotation/190129 $va

echo "Copy sumstats -- not used in pipeline"
# genetics-portal-dev-sumstats are static files we donâ€™t regenerate
$gscp -r gs://genetics-portal-dev-sumstats/filtered/pvalue_0.05/** $sa

echo "Copy credset -- not used in pipeline"
finemapping='210923'
$gscp -r $staging/finemapping/$finemapping/credset/* $outputs/v2d_credset/

echo "Done downloading"

echo $(gsutil ls -r $inputs)
```



